{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-06T15:16:27.407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from networks import *\n",
    "#from model_adv import *\n",
    "#from cleverhans.attacks import FastGradientMethod\n",
    "#from cleverhans.model import Model,CallableModelWrapper\n",
    "from foolbox.models import TensorFlowModel\n",
    "\n",
    "train_images = mnist.train_images()/255\n",
    "train_labels = mnist.train_labels()\n",
    "a = train_labels\n",
    "b = np.zeros((len(a), 10))\n",
    "b[np.arange(len(a)), a] = 1\n",
    "train_labels = b\n",
    "\n",
    "test_images = mnist.test_images()/255\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-06T15:16:27.414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/laurent/Projets/Defence_cnn/networks.py:64: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 0/20] [   0/ 890] time: 0.2422,loss_1: 2.22280216, loss_2: 2.22280216\n",
      "Epoch: [ 0/20] [  10/ 890] time: 5.2213,loss_1: 1.36925435, loss_2: 1.36925435\n",
      "Epoch: [ 0/20] [  20/ 890] time: 10.2711,loss_1: 0.44201142, loss_2: 0.44201142\n",
      "Epoch: [ 0/20] [  30/ 890] time: 15.2847,loss_1: 0.32982573, loss_2: 0.32982573\n",
      "Epoch: [ 0/20] [  40/ 890] time: 20.6274,loss_1: 0.17780456, loss_2: 0.17780456\n",
      "Epoch: [ 0/20] [  50/ 890] time: 25.5106,loss_1: 0.10395330, loss_2: 0.10395330\n",
      "Epoch: [ 0/20] [  60/ 890] time: 30.4341,loss_1: 0.11251032, loss_2: 0.11251032\n",
      "Epoch: [ 0/20] [  70/ 890] time: 35.8086,loss_1: 0.11007357, loss_2: 0.11007357\n",
      "Epoch: [ 0/20] [  80/ 890] time: 40.1721,loss_1: 0.11856346, loss_2: 0.11856346\n",
      "Epoch: [ 0/20] [  90/ 890] time: 44.5649,loss_1: 0.08542022, loss_2: 0.08542022\n",
      "Epoch: [ 0/20] [ 100/ 890] time: 48.9144,loss_1: 0.03771703, loss_2: 0.03771703\n",
      "Epoch: [ 0/20] [ 110/ 890] time: 53.3097,loss_1: 0.03819013, loss_2: 0.03819013\n",
      "Epoch: [ 0/20] [ 120/ 890] time: 57.9424,loss_1: 0.02979853, loss_2: 0.02979853\n",
      "Epoch: [ 0/20] [ 130/ 890] time: 62.4158,loss_1: 0.13601130, loss_2: 0.13601130\n",
      "Epoch: [ 0/20] [ 140/ 890] time: 66.7464,loss_1: 0.09304319, loss_2: 0.09304319\n",
      "Epoch: [ 0/20] [ 150/ 890] time: 71.3063,loss_1: 0.11565185, loss_2: 0.11565185\n",
      "Epoch: [ 0/20] [ 160/ 890] time: 76.2106,loss_1: 0.03480829, loss_2: 0.03480829\n",
      "Epoch: [ 0/20] [ 170/ 890] time: 80.6833,loss_1: 0.06815412, loss_2: 0.06815412\n",
      "Epoch: [ 0/20] [ 180/ 890] time: 84.9104,loss_1: 0.07817805, loss_2: 0.07817805\n",
      "Epoch: [ 0/20] [ 190/ 890] time: 89.4195,loss_1: 0.08453954, loss_2: 0.08453954\n",
      "Epoch: [ 0/20] [ 200/ 890] time: 93.2510,loss_1: 0.02473610, loss_2: 0.02473610\n",
      "Epoch: [ 0/20] [ 210/ 890] time: 96.9035,loss_1: 0.05284571, loss_2: 0.05284571\n",
      "Epoch: [ 0/20] [ 220/ 890] time: 100.6413,loss_1: 0.02578843, loss_2: 0.02578843\n",
      "Epoch: [ 0/20] [ 230/ 890] time: 104.8406,loss_1: 0.02641176, loss_2: 0.02641176\n",
      "Epoch: [ 0/20] [ 240/ 890] time: 110.3740,loss_1: 0.00735636, loss_2: 0.00735636\n",
      "Epoch: [ 0/20] [ 250/ 890] time: 114.9017,loss_1: 0.01746590, loss_2: 0.01746590\n",
      "Epoch: [ 0/20] [ 260/ 890] time: 118.5801,loss_1: 0.01465060, loss_2: 0.01465060\n",
      "Epoch: [ 0/20] [ 270/ 890] time: 122.0020,loss_1: 0.01666616, loss_2: 0.01666616\n",
      "Epoch: [ 0/20] [ 280/ 890] time: 125.5178,loss_1: 0.06472015, loss_2: 0.06472015\n",
      "Epoch: [ 0/20] [ 290/ 890] time: 129.8624,loss_1: 0.02354663, loss_2: 0.02354663\n",
      "Epoch: [ 0/20] [ 300/ 890] time: 135.0545,loss_1: 0.03699941, loss_2: 0.03699941\n",
      "Epoch: [ 0/20] [ 310/ 890] time: 140.6413,loss_1: 0.02412776, loss_2: 0.02412776\n",
      "Epoch: [ 0/20] [ 320/ 890] time: 146.4762,loss_1: 0.01234232, loss_2: 0.01234232\n",
      "Epoch: [ 0/20] [ 330/ 890] time: 150.0530,loss_1: 0.01692714, loss_2: 0.01692714\n",
      "Epoch: [ 0/20] [ 340/ 890] time: 153.3952,loss_1: 0.04030814, loss_2: 0.04030814\n",
      "Epoch: [ 0/20] [ 350/ 890] time: 156.7082,loss_1: 0.01375302, loss_2: 0.01375302\n",
      "Epoch: [ 0/20] [ 360/ 890] time: 160.0549,loss_1: 0.04162066, loss_2: 0.04162066\n",
      "Epoch: [ 0/20] [ 370/ 890] time: 163.5495,loss_1: 0.00916324, loss_2: 0.00916324\n",
      "Epoch: [ 0/20] [ 380/ 890] time: 166.9788,loss_1: 0.00620046, loss_2: 0.00620046\n",
      "Epoch: [ 0/20] [ 390/ 890] time: 170.4183,loss_1: 0.00753570, loss_2: 0.00753570\n",
      "Epoch: [ 0/20] [ 400/ 890] time: 173.8892,loss_1: 0.04331568, loss_2: 0.04331568\n",
      "Epoch: [ 0/20] [ 410/ 890] time: 177.3544,loss_1: 0.02334177, loss_2: 0.02334177\n",
      "Epoch: [ 0/20] [ 420/ 890] time: 180.9735,loss_1: 0.01301944, loss_2: 0.01301944\n",
      "Epoch: [ 0/20] [ 430/ 890] time: 184.9784,loss_1: 0.03287550, loss_2: 0.03287550\n",
      "Epoch: [ 0/20] [ 440/ 890] time: 188.4844,loss_1: 0.01549016, loss_2: 0.01549016\n",
      "Epoch: [ 0/20] [ 450/ 890] time: 191.9467,loss_1: 0.02218208, loss_2: 0.02218208\n",
      "Epoch: [ 0/20] [ 460/ 890] time: 195.5016,loss_1: 0.01879909, loss_2: 0.01879909\n",
      "Epoch: [ 0/20] [ 470/ 890] time: 199.4633,loss_1: 0.02683918, loss_2: 0.02683918\n",
      "Epoch: [ 0/20] [ 480/ 890] time: 204.0796,loss_1: 0.02215721, loss_2: 0.02215721\n",
      "Epoch: [ 0/20] [ 490/ 890] time: 208.0360,loss_1: 0.00910796, loss_2: 0.00910796\n",
      "Epoch: [ 0/20] [ 500/ 890] time: 212.3307,loss_1: 0.01083019, loss_2: 0.01083019\n",
      "Epoch: [ 0/20] [ 510/ 890] time: 216.3401,loss_1: 0.01047209, loss_2: 0.01047209\n",
      "Epoch: [ 0/20] [ 520/ 890] time: 220.1220,loss_1: 0.01771375, loss_2: 0.01771375\n",
      "Epoch: [ 0/20] [ 530/ 890] time: 225.1415,loss_1: 0.01109624, loss_2: 0.01109624\n",
      "Epoch: [ 0/20] [ 540/ 890] time: 231.0535,loss_1: 0.00960067, loss_2: 0.00960067\n",
      "Epoch: [ 0/20] [ 550/ 890] time: 236.2596,loss_1: 0.02747835, loss_2: 0.02747835\n",
      "Epoch: [ 0/20] [ 560/ 890] time: 240.3714,loss_1: 0.01001132, loss_2: 0.01001132\n",
      "Epoch: [ 0/20] [ 570/ 890] time: 244.1581,loss_1: 0.01337873, loss_2: 0.01337873\n",
      "Epoch: [ 0/20] [ 580/ 890] time: 248.2842,loss_1: 0.00546834, loss_2: 0.00546834\n",
      "Epoch: [ 0/20] [ 590/ 890] time: 251.5825,loss_1: 0.02799611, loss_2: 0.02799611\n",
      "Epoch: [ 0/20] [ 600/ 890] time: 254.9337,loss_1: 0.01382860, loss_2: 0.01382860\n",
      "Epoch: [ 0/20] [ 610/ 890] time: 258.2173,loss_1: 0.01773907, loss_2: 0.01773907\n",
      "Epoch: [ 0/20] [ 620/ 890] time: 261.5059,loss_1: 0.03652941, loss_2: 0.03652941\n",
      "Epoch: [ 0/20] [ 630/ 890] time: 264.8017,loss_1: 0.00914113, loss_2: 0.00914113\n",
      "Epoch: [ 0/20] [ 640/ 890] time: 268.1720,loss_1: 0.00700500, loss_2: 0.00700500\n",
      "Epoch: [ 0/20] [ 650/ 890] time: 271.6652,loss_1: 0.00632015, loss_2: 0.00632015\n",
      "Epoch: [ 0/20] [ 660/ 890] time: 276.7877,loss_1: 0.01437752, loss_2: 0.01437752\n",
      "Epoch: [ 0/20] [ 670/ 890] time: 280.9889,loss_1: 0.02074305, loss_2: 0.02074305\n",
      "Epoch: [ 0/20] [ 680/ 890] time: 286.0814,loss_1: 0.00690357, loss_2: 0.00690357\n",
      "Epoch: [ 0/20] [ 690/ 890] time: 290.1102,loss_1: 0.02674229, loss_2: 0.02674229\n",
      "Epoch: [ 0/20] [ 700/ 890] time: 293.8875,loss_1: 0.00663077, loss_2: 0.00663077\n",
      "Epoch: [ 0/20] [ 710/ 890] time: 298.3694,loss_1: 0.00220624, loss_2: 0.00220624\n",
      "Epoch: [ 0/20] [ 720/ 890] time: 303.2319,loss_1: 0.01384668, loss_2: 0.01384668\n",
      "Epoch: [ 0/20] [ 730/ 890] time: 306.8045,loss_1: 0.00702733, loss_2: 0.00702733\n",
      "Epoch: [ 0/20] [ 740/ 890] time: 310.3555,loss_1: 0.02153259, loss_2: 0.02153259\n",
      "Epoch: [ 0/20] [ 750/ 890] time: 314.0591,loss_1: 0.00671754, loss_2: 0.00671754\n",
      "Epoch: [ 0/20] [ 760/ 890] time: 317.5827,loss_1: 0.01273868, loss_2: 0.01273868\n",
      "Epoch: [ 0/20] [ 770/ 890] time: 321.1142,loss_1: 0.01173854, loss_2: 0.01173854\n",
      "Epoch: [ 0/20] [ 780/ 890] time: 324.9754,loss_1: 0.01283170, loss_2: 0.01283170\n",
      "Epoch: [ 0/20] [ 790/ 890] time: 328.6209,loss_1: 0.02640793, loss_2: 0.02640793\n",
      "Epoch: [ 0/20] [ 800/ 890] time: 332.2328,loss_1: 0.00608398, loss_2: 0.00608398\n",
      "Epoch: [ 0/20] [ 810/ 890] time: 336.0352,loss_1: 0.00578452, loss_2: 0.00578452\n",
      "Epoch: [ 0/20] [ 820/ 890] time: 339.7888,loss_1: 0.01465650, loss_2: 0.01465650\n",
      "Epoch: [ 0/20] [ 830/ 890] time: 343.3486,loss_1: 0.01098229, loss_2: 0.01098229\n",
      "Epoch: [ 0/20] [ 840/ 890] time: 347.0496,loss_1: 0.00948587, loss_2: 0.00948587\n",
      "Epoch: [ 0/20] [ 850/ 890] time: 351.1865,loss_1: 0.00911116, loss_2: 0.00911116\n",
      "Epoch: [ 0/20] [ 860/ 890] time: 355.2653,loss_1: 0.01072888, loss_2: 0.01072888\n",
      "Epoch: [ 0/20] [ 870/ 890] time: 359.0712,loss_1: 0.00684780, loss_2: 0.00684780\n",
      "Epoch: [ 0/20] [ 880/ 890] time: 363.5395,loss_1: 0.01043623, loss_2: 0.01043623\n",
      "Epoch: [ 1/20] [   0/ 890] time: 425.0532,loss_1: 0.00827779, loss_2: 0.00827779\n",
      "Epoch: [ 1/20] [  10/ 890] time: 429.0676,loss_1: 0.00662667, loss_2: 0.00662667\n",
      "Epoch: [ 1/20] [  20/ 890] time: 432.5640,loss_1: 0.01641135, loss_2: 0.01641135\n",
      "Epoch: [ 1/20] [  30/ 890] time: 437.1680,loss_1: 0.00808311, loss_2: 0.00808311\n",
      "Epoch: [ 1/20] [  40/ 890] time: 441.9138,loss_1: 0.01120358, loss_2: 0.01120358\n",
      "Epoch: [ 1/20] [  50/ 890] time: 446.0846,loss_1: 0.01064096, loss_2: 0.01064096\n",
      "Epoch: [ 1/20] [  60/ 890] time: 450.3697,loss_1: 0.00407446, loss_2: 0.00407446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/20] [  70/ 890] time: 454.9755,loss_1: 0.00604713, loss_2: 0.00604713\n",
      "Epoch: [ 1/20] [  80/ 890] time: 459.9150,loss_1: 0.00895051, loss_2: 0.00895051\n",
      "Epoch: [ 1/20] [  90/ 890] time: 464.4048,loss_1: 0.00706671, loss_2: 0.00706671\n",
      "Epoch: [ 1/20] [ 100/ 890] time: 468.7012,loss_1: 0.00797102, loss_2: 0.00797102\n",
      "Epoch: [ 1/20] [ 110/ 890] time: 472.5514,loss_1: 0.00547384, loss_2: 0.00547384\n",
      "Epoch: [ 1/20] [ 120/ 890] time: 476.6298,loss_1: 0.00218471, loss_2: 0.00218471\n",
      "Epoch: [ 1/20] [ 130/ 890] time: 481.5727,loss_1: 0.01406650, loss_2: 0.01406650\n",
      "Epoch: [ 1/20] [ 140/ 890] time: 485.5266,loss_1: 0.01239979, loss_2: 0.01239979\n",
      "Epoch: [ 1/20] [ 150/ 890] time: 489.5109,loss_1: 0.00674324, loss_2: 0.00674324\n",
      "Epoch: [ 1/20] [ 160/ 890] time: 492.8792,loss_1: 0.00875006, loss_2: 0.00875006\n",
      "Epoch: [ 1/20] [ 170/ 890] time: 496.2053,loss_1: 0.00649613, loss_2: 0.00649613\n",
      "Epoch: [ 1/20] [ 180/ 890] time: 499.5034,loss_1: 0.01072250, loss_2: 0.01072250\n",
      "Epoch: [ 1/20] [ 190/ 890] time: 503.5382,loss_1: 0.01005726, loss_2: 0.01005726\n",
      "Epoch: [ 1/20] [ 200/ 890] time: 507.0760,loss_1: 0.00539894, loss_2: 0.00539894\n",
      "Epoch: [ 1/20] [ 210/ 890] time: 510.4271,loss_1: 0.00460011, loss_2: 0.00460011\n",
      "Epoch: [ 1/20] [ 220/ 890] time: 513.8254,loss_1: 0.00398421, loss_2: 0.00398421\n",
      "Epoch: [ 1/20] [ 230/ 890] time: 517.2864,loss_1: 0.00402368, loss_2: 0.00402368\n",
      "Epoch: [ 1/20] [ 240/ 890] time: 520.6296,loss_1: 0.00237023, loss_2: 0.00237023\n",
      "Epoch: [ 1/20] [ 250/ 890] time: 524.0017,loss_1: 0.00219671, loss_2: 0.00219671\n",
      "Epoch: [ 1/20] [ 260/ 890] time: 527.3357,loss_1: 0.00311168, loss_2: 0.00311168\n",
      "Epoch: [ 1/20] [ 270/ 890] time: 530.6874,loss_1: 0.00626467, loss_2: 0.00626467\n",
      "Epoch: [ 1/20] [ 280/ 890] time: 534.0553,loss_1: 0.01250647, loss_2: 0.01250647\n",
      "Epoch: [ 1/20] [ 290/ 890] time: 537.3813,loss_1: 0.00507264, loss_2: 0.00507264\n",
      "Epoch: [ 1/20] [ 300/ 890] time: 540.6976,loss_1: 0.03034312, loss_2: 0.03034312\n",
      "Epoch: [ 1/20] [ 310/ 890] time: 544.0752,loss_1: 0.00429598, loss_2: 0.00429598\n",
      "Epoch: [ 1/20] [ 320/ 890] time: 547.4102,loss_1: 0.00332944, loss_2: 0.00332944\n",
      "Epoch: [ 1/20] [ 330/ 890] time: 550.7321,loss_1: 0.00325795, loss_2: 0.00325795\n",
      "Epoch: [ 1/20] [ 340/ 890] time: 554.0557,loss_1: 0.00945494, loss_2: 0.00945494\n",
      "Epoch: [ 1/20] [ 350/ 890] time: 557.4006,loss_1: 0.00431126, loss_2: 0.00431126\n",
      "Epoch: [ 1/20] [ 360/ 890] time: 560.7514,loss_1: 0.00257138, loss_2: 0.00257138\n",
      "Epoch: [ 1/20] [ 370/ 890] time: 564.0852,loss_1: 0.00328796, loss_2: 0.00328796\n",
      "Epoch: [ 1/20] [ 380/ 890] time: 567.4146,loss_1: 0.00112086, loss_2: 0.00112086\n",
      "Epoch: [ 1/20] [ 390/ 890] time: 570.7382,loss_1: 0.00138742, loss_2: 0.00138742\n",
      "Epoch: [ 1/20] [ 400/ 890] time: 574.2121,loss_1: 0.01326502, loss_2: 0.01326502\n",
      "Epoch: [ 1/20] [ 410/ 890] time: 577.5358,loss_1: 0.00764521, loss_2: 0.00764521\n",
      "Epoch: [ 1/20] [ 420/ 890] time: 580.9106,loss_1: 0.00252624, loss_2: 0.00252624\n",
      "Epoch: [ 1/20] [ 430/ 890] time: 584.4102,loss_1: 0.00896955, loss_2: 0.00896955\n",
      "Epoch: [ 1/20] [ 440/ 890] time: 587.7708,loss_1: 0.01763216, loss_2: 0.01763216\n",
      "Epoch: [ 1/20] [ 450/ 890] time: 591.1323,loss_1: 0.00675934, loss_2: 0.00675934\n",
      "Epoch: [ 1/20] [ 460/ 890] time: 594.4910,loss_1: 0.01214133, loss_2: 0.01214133\n",
      "Epoch: [ 1/20] [ 470/ 890] time: 597.8776,loss_1: 0.01432753, loss_2: 0.01432753\n",
      "Epoch: [ 1/20] [ 480/ 890] time: 601.1939,loss_1: 0.00429855, loss_2: 0.00429855\n",
      "Epoch: [ 1/20] [ 490/ 890] time: 604.5269,loss_1: 0.00165078, loss_2: 0.00165078\n",
      "Epoch: [ 1/20] [ 500/ 890] time: 607.9308,loss_1: 0.00377536, loss_2: 0.00377536\n",
      "Epoch: [ 1/20] [ 510/ 890] time: 611.3154,loss_1: 0.00212051, loss_2: 0.00212051\n",
      "Epoch: [ 1/20] [ 520/ 890] time: 614.6677,loss_1: 0.00547691, loss_2: 0.00547691\n",
      "Epoch: [ 1/20] [ 530/ 890] time: 618.0176,loss_1: 0.00288367, loss_2: 0.00288367\n",
      "Epoch: [ 1/20] [ 540/ 890] time: 621.3376,loss_1: 0.00218119, loss_2: 0.00218119\n",
      "Epoch: [ 1/20] [ 550/ 890] time: 624.6673,loss_1: 0.00900881, loss_2: 0.00900881\n",
      "Epoch: [ 1/20] [ 560/ 890] time: 628.1005,loss_1: 0.00468025, loss_2: 0.00468025\n",
      "Epoch: [ 1/20] [ 570/ 890] time: 631.4609,loss_1: 0.00816178, loss_2: 0.00816178\n",
      "Epoch: [ 1/20] [ 580/ 890] time: 634.8052,loss_1: 0.00048776, loss_2: 0.00048776\n",
      "Epoch: [ 1/20] [ 590/ 890] time: 638.1186,loss_1: 0.00409555, loss_2: 0.00409555\n",
      "Epoch: [ 1/20] [ 600/ 890] time: 641.4559,loss_1: 0.00585832, loss_2: 0.00585832\n",
      "Epoch: [ 1/20] [ 610/ 890] time: 644.9490,loss_1: 0.00766427, loss_2: 0.00766427\n",
      "Epoch: [ 1/20] [ 620/ 890] time: 648.3115,loss_1: 0.01993019, loss_2: 0.01993019\n",
      "Epoch: [ 1/20] [ 630/ 890] time: 651.6313,loss_1: 0.00419530, loss_2: 0.00419530\n",
      "Epoch: [ 1/20] [ 640/ 890] time: 654.9563,loss_1: 0.00215752, loss_2: 0.00215752\n",
      "Epoch: [ 1/20] [ 650/ 890] time: 658.3276,loss_1: 0.00376610, loss_2: 0.00376610\n",
      "Epoch: [ 1/20] [ 660/ 890] time: 661.6566,loss_1: 0.00610616, loss_2: 0.00610616\n",
      "Epoch: [ 1/20] [ 670/ 890] time: 664.9962,loss_1: 0.01123124, loss_2: 0.01123124\n",
      "Epoch: [ 1/20] [ 680/ 890] time: 668.2906,loss_1: 0.00527946, loss_2: 0.00527946\n",
      "Epoch: [ 1/20] [ 690/ 890] time: 671.6395,loss_1: 0.01649366, loss_2: 0.01649366\n",
      "Epoch: [ 1/20] [ 700/ 890] time: 674.9992,loss_1: 0.00201618, loss_2: 0.00201618\n",
      "Epoch: [ 1/20] [ 710/ 890] time: 678.3412,loss_1: 0.00129144, loss_2: 0.00129144\n",
      "Epoch: [ 1/20] [ 720/ 890] time: 681.7508,loss_1: 0.00316785, loss_2: 0.00316785\n",
      "Epoch: [ 1/20] [ 730/ 890] time: 685.1847,loss_1: 0.00109575, loss_2: 0.00109575\n",
      "Epoch: [ 1/20] [ 740/ 890] time: 688.6453,loss_1: 0.00944958, loss_2: 0.00944958\n",
      "Epoch: [ 1/20] [ 750/ 890] time: 692.5043,loss_1: 0.00193741, loss_2: 0.00193741\n",
      "Epoch: [ 1/20] [ 760/ 890] time: 695.9352,loss_1: 0.00773376, loss_2: 0.00773376\n",
      "Epoch: [ 1/20] [ 770/ 890] time: 699.3629,loss_1: 0.00590219, loss_2: 0.00590219\n",
      "Epoch: [ 1/20] [ 780/ 890] time: 702.7525,loss_1: 0.00425205, loss_2: 0.00425205\n",
      "Epoch: [ 1/20] [ 790/ 890] time: 706.5114,loss_1: 0.01133003, loss_2: 0.01133003\n",
      "Epoch: [ 1/20] [ 800/ 890] time: 709.9493,loss_1: 0.00131476, loss_2: 0.00131476\n",
      "Epoch: [ 1/20] [ 810/ 890] time: 713.3480,loss_1: 0.00181741, loss_2: 0.00181741\n",
      "Epoch: [ 1/20] [ 820/ 890] time: 716.8600,loss_1: 0.00415171, loss_2: 0.00415171\n",
      "Epoch: [ 1/20] [ 830/ 890] time: 720.4852,loss_1: 0.00870441, loss_2: 0.00870441\n",
      "Epoch: [ 1/20] [ 840/ 890] time: 724.0309,loss_1: 0.00420281, loss_2: 0.00420281\n",
      "Epoch: [ 1/20] [ 850/ 890] time: 727.5899,loss_1: 0.00850472, loss_2: 0.00850472\n",
      "Epoch: [ 1/20] [ 860/ 890] time: 731.1095,loss_1: 0.00317354, loss_2: 0.00317354\n",
      "Epoch: [ 1/20] [ 870/ 890] time: 734.6642,loss_1: 0.00309338, loss_2: 0.00309338\n",
      "Epoch: [ 1/20] [ 880/ 890] time: 738.2172,loss_1: 0.00222018, loss_2: 0.00222018\n",
      "Epoch: [ 2/20] [   0/ 890] time: 791.7686,loss_1: 0.00354764, loss_2: 0.00354764\n",
      "Epoch: [ 2/20] [  10/ 890] time: 795.1541,loss_1: 0.00188349, loss_2: 0.00188349\n",
      "Epoch: [ 2/20] [  20/ 890] time: 798.4642,loss_1: 0.00575968, loss_2: 0.00575968\n",
      "Epoch: [ 2/20] [  30/ 890] time: 801.7788,loss_1: 0.00385161, loss_2: 0.00385161\n",
      "Epoch: [ 2/20] [  40/ 890] time: 805.0813,loss_1: 0.00939510, loss_2: 0.00939510\n",
      "Epoch: [ 2/20] [  50/ 890] time: 808.4054,loss_1: 0.00380520, loss_2: 0.00380520\n",
      "Epoch: [ 2/20] [  60/ 890] time: 811.7608,loss_1: 0.00106838, loss_2: 0.00106838\n",
      "Epoch: [ 2/20] [  70/ 890] time: 815.0797,loss_1: 0.00179850, loss_2: 0.00179850\n",
      "Epoch: [ 2/20] [  80/ 890] time: 818.4646,loss_1: 0.00263794, loss_2: 0.00263794\n",
      "Epoch: [ 2/20] [  90/ 890] time: 821.8877,loss_1: 0.00133578, loss_2: 0.00133578\n",
      "Epoch: [ 2/20] [ 100/ 890] time: 825.4679,loss_1: 0.00244387, loss_2: 0.00244387\n",
      "Epoch: [ 2/20] [ 110/ 890] time: 828.8774,loss_1: 0.00316423, loss_2: 0.00316423\n",
      "Epoch: [ 2/20] [ 120/ 890] time: 832.2493,loss_1: 0.00153724, loss_2: 0.00153724\n",
      "Epoch: [ 2/20] [ 130/ 890] time: 835.6025,loss_1: 0.00706556, loss_2: 0.00706556\n",
      "Epoch: [ 2/20] [ 140/ 890] time: 838.9717,loss_1: 0.00418913, loss_2: 0.00418913\n",
      "Epoch: [ 2/20] [ 150/ 890] time: 842.3139,loss_1: 0.00214244, loss_2: 0.00214244\n",
      "Epoch: [ 2/20] [ 160/ 890] time: 845.6059,loss_1: 0.00342128, loss_2: 0.00342128\n",
      "Epoch: [ 2/20] [ 170/ 890] time: 848.8994,loss_1: 0.00336168, loss_2: 0.00336168\n",
      "Epoch: [ 2/20] [ 180/ 890] time: 852.2444,loss_1: 0.00384855, loss_2: 0.00384855\n",
      "Epoch: [ 2/20] [ 190/ 890] time: 855.5580,loss_1: 0.00608736, loss_2: 0.00608736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 2/20] [ 200/ 890] time: 858.8492,loss_1: 0.00511706, loss_2: 0.00511706\n",
      "Epoch: [ 2/20] [ 210/ 890] time: 862.1559,loss_1: 0.00206212, loss_2: 0.00206212\n",
      "Epoch: [ 2/20] [ 220/ 890] time: 865.6101,loss_1: 0.00213533, loss_2: 0.00213533\n",
      "Epoch: [ 2/20] [ 230/ 890] time: 868.9107,loss_1: 0.00220053, loss_2: 0.00220053\n",
      "Epoch: [ 2/20] [ 240/ 890] time: 872.2574,loss_1: 0.00100459, loss_2: 0.00100459\n",
      "Epoch: [ 2/20] [ 250/ 890] time: 875.6761,loss_1: 0.00195427, loss_2: 0.00195427\n",
      "Epoch: [ 2/20] [ 260/ 890] time: 879.0020,loss_1: 0.00091382, loss_2: 0.00091382\n",
      "Epoch: [ 2/20] [ 270/ 890] time: 882.3818,loss_1: 0.00434965, loss_2: 0.00434965\n",
      "Epoch: [ 2/20] [ 280/ 890] time: 886.2996,loss_1: 0.00325216, loss_2: 0.00325216\n",
      "Epoch: [ 2/20] [ 290/ 890] time: 890.2035,loss_1: 0.00221516, loss_2: 0.00221516\n",
      "Epoch: [ 2/20] [ 300/ 890] time: 893.6170,loss_1: 0.00918917, loss_2: 0.00918917\n",
      "Epoch: [ 2/20] [ 310/ 890] time: 897.0473,loss_1: 0.00227439, loss_2: 0.00227439\n",
      "Epoch: [ 2/20] [ 320/ 890] time: 900.7631,loss_1: 0.00358021, loss_2: 0.00358021\n",
      "Epoch: [ 2/20] [ 330/ 890] time: 905.3680,loss_1: 0.00348067, loss_2: 0.00348067\n",
      "Epoch: [ 2/20] [ 340/ 890] time: 909.0270,loss_1: 0.00280626, loss_2: 0.00280626\n",
      "Epoch: [ 2/20] [ 350/ 890] time: 912.5339,loss_1: 0.00140508, loss_2: 0.00140508\n",
      "Epoch: [ 2/20] [ 360/ 890] time: 916.0409,loss_1: 0.00084321, loss_2: 0.00084321\n",
      "Epoch: [ 2/20] [ 370/ 890] time: 919.4790,loss_1: 0.00123567, loss_2: 0.00123567\n",
      "Epoch: [ 2/20] [ 380/ 890] time: 922.9810,loss_1: 0.00098036, loss_2: 0.00098036\n",
      "Epoch: [ 2/20] [ 390/ 890] time: 926.5835,loss_1: 0.00083972, loss_2: 0.00083972\n",
      "Epoch: [ 2/20] [ 400/ 890] time: 931.1935,loss_1: 0.00588317, loss_2: 0.00588317\n",
      "Epoch: [ 2/20] [ 410/ 890] time: 935.4778,loss_1: 0.00593692, loss_2: 0.00593692\n",
      "Epoch: [ 2/20] [ 420/ 890] time: 939.8352,loss_1: 0.00227262, loss_2: 0.00227262\n",
      "Epoch: [ 2/20] [ 430/ 890] time: 944.6194,loss_1: 0.00608928, loss_2: 0.00608928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "run_config = tf.ConfigProto()\n",
    "run_config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=run_config)\n",
    "\n",
    "cnn = CNN(sess,\n",
    "            y_dim=10,\n",
    "            batch_size=64,\n",
    "            epoch=20,\n",
    "            learning_rate=0.002,\n",
    "            beta=.5,\n",
    "            model_name='CNN',\n",
    "            checkpoint_dir=\"checkpoint\")\n",
    "\n",
    "\n",
    "cnn.train(train_images, train_labels)\n",
    "#\n",
    "# grad = tf.gradients(cnn.global_loss, cnn.inputs)[0]\n",
    "# a=grad.eval({\n",
    "#     cnn.inputs: train_images[:2].reshape(tuple([-1]+cnn.input_shape)),\n",
    "#     cnn.labels: train_labels[:2],\n",
    "#     cnn.mode: 'TEST'\n",
    "# })\n",
    "#\n",
    "# #y_pred = np.argmax(dcgan.predict(test_images), axis=1)\n",
    "# model=CallableModelWrapper(cnn.predict, output_layer='logits')\n",
    "#\n",
    "#\n",
    "#\n",
    "# fgm=FastGradientMethod(model,sess=sess)\n",
    "#\n",
    "# fgm_params = {'eps': 0.3,\n",
    "#                'clip_min': 0.,\n",
    "#                'clip_max': 1.}\n",
    "#\n",
    "# adv_x = fgm.generate((train_images[:2]), **fgm_params)\n",
    "# preds_adv = model.get_probs(adv_x)\n",
    "\n",
    "\n",
    "\n",
    "# model = TensorFlowModel(cnn.inputs,cnn.network,bounds=(0, 255))\n",
    "\n",
    "# from foolbox.criteria import TargetClassProbability\n",
    "\n",
    "# target_class = 9\n",
    "# criterion = TargetClassProbability(target_class, p=0.99)\n",
    "\n",
    "\n",
    "# from foolbox.attacks import FGSM\n",
    "\n",
    "\n",
    "# attack=FGSM(model)\n",
    "# image = train_images[0].reshape((28, 28, 1))\n",
    "# label = np.argmax(model.predictions(image))\n",
    "\n",
    "# adversarial = attack(image,label=label,epsilons=1,max_epsilon=0.03*255)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.imshow(image.reshape((28, 28)), cmap='gray',vmin=0, vmax=255)\n",
    "# plt.gca().set_title(label)\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow(adversarial.reshape((28, 28)), cmap='gray',vmin=0, vmax=255)\n",
    "# plt.gca().set_title(np.argmax(model.predictions(adversarial)))\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.imshow((adversarial - image).reshape((28, 28)), cmap='gray',vmin=0, vmax=255)\n",
    "\n",
    "\n",
    "# # embed=tf.get_default_graph().get_tensor_by_name(\"embedding/Relu:0\")\n",
    "\n",
    "# # pp=[-1]+ cnn.input_shape+[1]\n",
    "# # gradient_embedding = tf.concat([tf.reshape(\n",
    "# #                            tf.gradients(embed[:,i], cnn.inputs)[0],pp) for i in range(embed.shape[1])],axis=4)\n",
    "# # loss_2 = networks.representer_grad_loss(gradient_embedding)\n",
    "# # loss_2.eval({\n",
    "# #     cnn.inputs: train_images[:100].reshape(tuple([-1]+ cnn.input_shape)),\n",
    "# #     cnn.labels: train_labels[:100],\n",
    "# #     cnn.mode: \"TEST\"\n",
    "# # })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-06T15:16:27.420Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
